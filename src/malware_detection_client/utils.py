import os
import sys
import json
import subprocess
import logging
import requests

logging.basicConfig(format="%(asctime)s:%(levelname)s:%(message)s")
logger = logging.getLogger('malware_detection_client')
logger.setLevel(logging.getLevelName('INFO'))

CONF_FILE_TEMPLATE = """# Where values are provided for the options, these are the defaults

[client]
# Client log level.  Valid options are DEBUG, INFO, WARNING, ERROR, CRITICAL
#log_level=INFO

# Scan the files on this system?
#scan_filesystem=True

# Scan the processes on this system?
#scan_processes=True

# Add extra metadata to each scan match, eg file type, file md5sum, matching line numbers, process name
#metadata=True

# Location of the rules.  Can be any of:
# - the name of a file on the local filesystem containing rules
# - a URL for an endpoint to download a list of rules via GraphQL
# - a URL to download a file containing rules
#rules_location=/tmp/malware_detection_rules.yar
#rules_location=http://127.0.0.1:3000/api/malware-detection/v1/graphql
#rules_location=http://127.0.0.1:3000/api/malware-detection/v1/signatures.yar
rules_location=%s

# A GraphQL endpoint for sending the results of a scan, eg:
#results_location=http://127.0.0.1:3000/api/malware-detection/v1/graphql
results_location=%s

# Limit the number of string matches uploaded per rule, esp if there are a lot of matches for a file/PID
#string_match_limit=10

# Comma separated list of rules to exclude from the scan, eg SpammyRule, IrrelevantRule, just_because_rule
#exclude_rules=

# URL for your proxy
#proxy_url=


[yara]
# Specific location of the yara binary file.  Autodetected if not specified.  Example: /usr/local/bin/yara
#location=

# Abort a particular scan if it takes longer than scan_timeout seconds
#scan_timeout=3600

# Nice value to run yara as
#nice=19

# Number of CPU threads yara will use
#cpu_thread_limit=2


[auth]
# Subscription-manager certificate and key to use for authenticating to console.redhat.com
cert=/etc/pki/consumer/cert.pem
key=/etc/pki/consumer/key.pem
"""


def create_new_conf_file(new_conf_file, rules_location='', results_url=''):
    """
    Writes out a new configuration file including values for rules_location and results_url (if set)
    If new_conf_file already exists, it will be overwritten
    """
    conf_file_template = CONF_FILE_TEMPLATE % (rules_location, results_url)
    try:
        with open(new_conf_file, mode='w') as cf:
            cf.write(conf_file_template)
    except Exception as e:
        logger.error("Error writing config file: %s", e)
        sys.exit(1)

    logger.info("Created new configuration file in %s", new_conf_file)
    sys.exit(0)


def string_to_bool(s):
    return s.lower() in ("yes", "true", "t", "1")


def get_insights_id():
    """
    Get the machine_id from insights-client
    If the machine_id doesn't exist, return a dummy value for the time being
    """
    insights_id_file = '/etc/insights-client/machine-id'
    try:
        with open(insights_id_file) as f:
            return f.read()
    except Exception as e:
        logger.error('Error reading %s to obtain the insightsId: %s.  Is the machine registered with Insights?',
                     insights_id_file, str(e))
        return '11111111-1111-1111-1111-111111111111'  # dummy value
        # sys.exit(1)


def get_identity_header(account_number=None):
    from base64 import b64encode
    from socket import gethostname

    if account_number:
        identity = b64encode(json.dumps({'identity': {'account_number': account_number,
                                                      'system': {'cn': gethostname()}}
                                         }).encode('utf-8'))
        return {'x-rh-identity': identity}
    else:
        return {}


def create_session():
    # Create the requests session so it has a default timeout of 2 minutes
    # and retries failed connections 5 times
    from urllib3.util import Retry
    default_timeout = 120  # seconds

    class TimeoutHTTPAdapter(requests.adapters.HTTPAdapter):
        def __init__(self, *args, **kwargs):
            self.timeout = default_timeout
            if "timeout" in kwargs:
                self.timeout = kwargs["timeout"]
                del kwargs["timeout"]
            super(TimeoutHTTPAdapter, self).__init__(*args, **kwargs)

        def send(self, request, **kwargs):
            timeout = kwargs.get("timeout")
            if timeout is None:
                kwargs["timeout"] = self.timeout
            return super(TimeoutHTTPAdapter, self).send(request, **kwargs)

    session = requests.Session()
    adapter = TimeoutHTTPAdapter(max_retries=Retry(total=5, backoff_factor=1))
    session.mount('https://', adapter)
    session.mount('http://', adapter)
    return session


def find_yara():
    """
    Find the yara binary on the local system.  Use /usr/local/bin/yara if it couldn't be found in the search path.
    """
    for yara in ['/bin/yara', '/usr/bin/yara']:
        if os.path.isfile(yara):
            return yara

    output = run_cmd(['which', 'yara'])
    return output if output else "/usr/local/bin/yara"


def run_cmd(cmd):
    """
    cmd is a list containing the command and its arguments, eg
        ['/usr/bin/yara', '-s', '-r', '-C', '/tmp/rules.yar', 'thing_to_scan']
    Since cmd isn't executed via a shell, the full path to the command is necessary.
    universal_newlines means the output is treated as text strings, not binary strings
    """
    if not isinstance(cmd, list):
        logger.error("Command '%s' must be specified as a list of arguments", cmd)
        sys.exit(1)
    try:
        stdout, stderr = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE,
                                          universal_newlines=True).communicate()
        if stderr:
            raise Exception(stderr)
        return stdout.strip()
    except Exception as error:
        logger.error("Problem running command '%s': %s", cmd, str(error))
        return ""
