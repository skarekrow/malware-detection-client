import os
import sys
import subprocess
from malware_detection_client.utils import logger
from malware_detection_client.process_modification_time import walk_directory, walk_include_items, MTIME_DAYS

CONF_DIR = "/etc/malware-detection-client/"
INCLUDE_FILE = CONF_DIR + 'filesystem_include.txt'
EXCLUDE_FILE = CONF_DIR + 'filesystem_exclude.txt'
SCAN_RECENTLY_MODIFIED_FILES_ONLY = False


def get_toplevel_dirs():
    """
    Returns a list of the top level directories directly under root (/),
        minus linked directories or kernel virtual filesystems
    """
    virtual_filesystems = {'/cgroup', '/proc', '/selinux', '/sys'}
    toplevel_dirs = set(filter(lambda x: not os.path.islink(x), map(lambda x: "/" + x, os.listdir('/'))))
    return sorted(list(toplevel_dirs - virtual_filesystems))


def get_parent_dirs(item, parent_dir_list, base_case='/'):
    """
    Get a list of parent directories of a particular filesystem item, stopping at base_case (root by default)
    Eg for get_parent_dirs('/path/to/some/item', parent_dir_list) ->
        parent_dir_list = ['/path', '/path/to', '/path/to/some', '/path/to/some/item']
    """
    if item == base_case or item == '/':
        return
    get_parent_dirs(os.path.dirname(item), parent_dir_list, base_case)
    parent_dir_list.append(item)


def get_network_fs_mountpoints():
    """
    Returns a list of mountpoints of mounted network filesystems, if any eg NFS, CIFS, SMB, SSHFS, CEPH, GLUSTERFS, GFS
    Otherwise returns an empty list if no mounted network filesystems
    """
    mountpoints = []
    cmd = 'findmnt -t nfs,nfs4,cifs,smbfs,fuse.sshfs,ceph,glusterfs,gfs,gfs2 -n -o TARGET'
    try:
        stdout, stderr = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True).communicate()
        mountpoints = stdout.decode('utf-8').strip().split('\n') if stdout else []
    except subprocess.CalledProcessError as err:
        error = err.output.strip()
        logger.error("Unable to get network filesystem mountpoints: %s", error)
    logger.debug("Network filesystem mountpoints found: %s", mountpoints)
    return mountpoints


def process_include_file():
    """
    Process the include file to get list of directories to be scanned
    If there are no entries then get the list of top level directories under root (/),
        less the kernel virtual filesystems
    :return: a list of directories to be scanned.  It never returns an empty list.
    """
    default_values = get_toplevel_dirs()
    if not os.path.isfile(INCLUDE_FILE):
        logger.warning("Couldn't find include file '%s'.  Using default values: %s...", INCLUDE_FILE, default_values)
        return default_values

    logger.info("Parsing include file '%s' ...", INCLUDE_FILE)
    include_list = []
    for line in open(INCLUDE_FILE):
        line = line.strip()
        if not line or line.startswith('#'):
            continue
        include_item = os.path.normpath(line)
        if os.path.exists(include_item):
            # ignore the include_item if its not a full directory path
            if not include_item.startswith('/'):
                logger.debug("Skipping partial directory path '%s' ...", include_item)
                continue
            elif os.path.islink(include_item):
                logger.debug("Skipping link '%s' ...", include_item)
                continue
            elif include_item == '/':
                # Found / in include file.  No need to get the other items because / trumps all
                logger.debug("Including root directory (/).  Ignoring the other items ...")
                include_list = default_values
                break
            else:
                include_list.append(include_item)
        else:
            logger.debug("Skipping missing item '%s' ...", include_item)

    if not include_list:
        logger.debug("No items found in include file.  Using default values %s ...", default_values)
        include_list = default_values
    else:
        # Remove any duplicates and any children of parent directories before returning
        include_list = remove_child_items(sorted(list(set(include_list))))

    logger.debug("Include file items: %s", include_list)
    return include_list


def process_exclude_file():
    """
    Process the exclude file to get list of directories to NOT be scanned
    By default, a number of toplevel directories to be excluded already in the file, eg:
        /dev, /media, /mnt and /net as these usually contain external files
    :return: a list of directories to not be scanned if any, otherwise an empty list
    """
    default_values = ['/dev', '/media', '/mnt', '/net']
    if not os.path.isfile(EXCLUDE_FILE):
        logger.warning("Couldn't find exclude file '%s'.  Using default values: %s...", EXCLUDE_FILE, default_values)
        return default_values

    logger.info("Parsing exclude file '%s' ...", EXCLUDE_FILE)
    exclude_list = []
    for line in open(EXCLUDE_FILE):
        line = line.strip()
        if not line or line.startswith('#'):
            continue
        exclude_item = os.path.normpath(line)
        if os.path.exists(exclude_item):
            # ignore the exclude_item if its / or it isn't a full directory path
            if exclude_item == '/':
                logger.debug("Skipping root directory '/' ...")
                continue
            elif not exclude_item.startswith('/'):
                logger.debug("Skipping partial directory path '%s' ...", exclude_item)
                continue
            else:
                exclude_list.append(exclude_item)
        else:
            logger.debug("Skipping missing item '%s' ...", exclude_item)

    if not exclude_list:
        logger.debug("No items specified in exclude file")
    else:
        # Remove any duplicates and any children of parent directories before returning
        exclude_list = remove_child_items(sorted(list(set(exclude_list))))

    logger.debug("Exclude file items: %s", exclude_list)
    return exclude_list


def remove_child_items(item_list):
    """
    For a list of filesystem items, remove those items that are duplicates or children of other items
    Eg, for remove_child_items['/path/to/some/item/child', '/path/to/another/item', '/path/to/some/item']
        returns ['/path/to/another/item', '/path/to/some/item']
    If one if the items is root, then it wins
    Also, all items should be the full path starting at root (/).  Any that aren't are removed
    """
    if '/' in item_list:
        return ['/']

    # Remove duplicates and any non-full path items
    item_list = sorted(list(set(filter(lambda x: x.startswith('/'), item_list))))
    remove_items = set([])
    for i, item1 in enumerate(item_list[:-1]):
        for item2 in item_list[i + 1:]:
            if item1 != item2 and item2.startswith(item1 + '/'):
                remove_items.add(item2)
    for remove_item in remove_items:
        item_list.remove(remove_item)
    return sorted(list(set(item_list)))


def remove_included_excluded_items(included_items, excluded_items):
    """
    Go through the list of included items and remove any that are in the exclude list,
        or are children of excluded items (no need to scan an included item if its parent is to be excluded)
    """
    # Clean up the lists, just in case this hasn't been done already
    included_items = remove_child_items(included_items)
    excluded_items = remove_child_items(excluded_items)

    remove_items = set([])
    for included_item in included_items:
        for excluded_item in excluded_items:
            if excluded_item == included_item or included_item.startswith(excluded_item + '/'):
                remove_items.add(included_item)
    for remove_item in remove_items:
        included_items.remove(remove_item)
    return included_items


def process():
    """
    Process the include and exclude files.
    Build a dictionary of items to scan for each top level directory under root, eg
    scan_dict = {'/boot': {'include': ['/boot/include/me', ...], 'exclude: ['/boot/exclude/me', ...]},
                 '/etc': {'include': ['/etc/include/me', ...], 'exclude: ['/etc/exclude/me', ...]},
                 ...
    :return: scan_dict
    """
    # Get a list of excluded items from the exclude file and network filesystem mountpoints
    initial_exclude_list = process_exclude_file()
    network_fs_mountpoints = get_network_fs_mountpoints()
    final_exclude_list = remove_child_items(list(set(network_fs_mountpoints) | set(initial_exclude_list)))
    logger.debug("Final exclude items: %s", final_exclude_list)

    # Get a list of included items from the include file, minus the excluded items
    initial_include_list = process_include_file()
    final_include_list = remove_included_excluded_items(initial_include_list, final_exclude_list)
    logger.debug("Final include items: %s", final_include_list)
    if not final_include_list:
        logger.error("No items to scan because the exclude file cancels out all the items from the include file")
        sys.exit(1)

    # This is the dictionary that will hold all the items to scan (after processing the include and exclude items)
    # It will be keyed by each of the toplevel directories containing items to scan
    # yara will scan each of the toplevel dir's 'include' keys (if present), or just the toplevel dir itself
    scan_dict = {}

    # Populate the scan_dict by creating keys for each toplevel directory of the items to include/scan
    # Create an 'include' key for each toplevel directory containing items to include in that toplevel directory
    logger.debug("Populating scan_dict's include items ...")
    for include_item in final_include_list:
        item_subpaths = []
        get_parent_dirs(include_item, item_subpaths)
        include_item_toplevel_dir = item_subpaths[0]
        if include_item_toplevel_dir not in scan_dict:
            # Create an 'include' key if the item to scan isn't just the toplevel directory itself
            scan_dict[include_item_toplevel_dir] = {'include': {include_item}} if include_item != include_item_toplevel_dir else {}
        else:
            scan_dict[include_item_toplevel_dir]['include'].add(include_item)

    logger.debug("Scan dict after adding include items: %s", scan_dict)

    # Populate an 'exclude' key for the toplevel dirs in the scan_dict that also have items to exclude
    # Or remove the toplevel dirs from the scan dict where the toplevel dir itself is to be excluded
    logger.debug("Populating scan_dict's exclude items ...")
    for exclude_item in final_exclude_list:
        item_subpaths = []
        get_parent_dirs(exclude_item, item_subpaths)
        exclude_item_toplevel_dir = item_subpaths[0]
        if exclude_item_toplevel_dir not in scan_dict:
            # This exclude_item's toplevel dir isn't in the scan dict, so skip it (since its not being included)
            continue
        if 'exclude' not in scan_dict[exclude_item_toplevel_dir]:
            # Create the 'exclude' key if it doesn't already exist
            scan_dict[exclude_item_toplevel_dir]['exclude'] = {'items': [], 'subpaths': set([])}

        scan_dict[exclude_item_toplevel_dir]['exclude']['items'].append(exclude_item)

        # Add the list of subpaths leading to this exclude item.
        # The subpaths are needed later for listing the contents each subpath
        scan_dict[exclude_item_toplevel_dir]['exclude']['subpaths'].update(item_subpaths)

    logger.debug("Scan dict after adding exclude items: %s", scan_dict)

    # For each toplevel dir with items to exclude, re-populate the include key with directory content listings
    # of the subpaths, minus the items to exclude and only including items to include.  Yep, its complicated.
    # These directory listings will be used with yara's --scan-list option
    logger.debug("Re-populating scan_dict's include items with directory content listings to pass to yara ...")
    for toplevel_dir in scan_dict:
        if 'exclude' not in scan_dict[toplevel_dir]:
            continue

        # Get directory listings of each of the subpaths
        scan_items = set([])
        toplevel_dir_exclude = scan_dict[toplevel_dir]['exclude']
        for exclude_item in toplevel_dir_exclude['items']:
            subpaths = []
            get_parent_dirs(exclude_item, subpaths)
            for i, subpath in enumerate(subpaths[:-1]):
                dir_list = os.listdir(subpath)
                dir_list = sorted(map(lambda x: subpath + '/' + x, dir_list))
                dir_list.remove(subpaths[i + 1])
                scan_items.update(dir_list)

        # Go through the list of scan items and remove any exclude items or exclude item subpaths
        for scan_item in list(scan_items):
            for exclude_item in toplevel_dir_exclude['items']:
                if scan_item == exclude_item or scan_item.startswith(exclude_item + '/'):
                    scan_items.remove(scan_item)
                    break
            else:
                for exclude_subpath in toplevel_dir_exclude['subpaths']:
                    if scan_item == exclude_subpath:
                        scan_items.remove(scan_item)

        # If there is an include list, make sure the scan_items only include items in the include list
        if 'include' in scan_dict[toplevel_dir]:
            for maybe_include in list(scan_items):
                if os.path.islink(maybe_include) or (not os.path.isfile(maybe_include) and not os.path.isdir(maybe_include)):
                    scan_items.remove(maybe_include)
                    continue
                if any([maybe_include == definitely_include or maybe_include.startswith(definitely_include + '/')
                        for definitely_include in scan_dict[toplevel_dir]['include']]):
                    continue
                else:
                    scan_items.remove(maybe_include)

        # Overwrite the existing include key list with the new list of scan_items
        scan_dict[toplevel_dir]['include'] = sorted(list(scan_items))

    logger.debug("Final scan_dict: %s", scan_dict)
    return scan_dict


def scan(scan_dict):
    import time
    from tempfile import NamedTemporaryFile

    logger.info("Starting filesystem scan ...")
    fs_scan_start = time.time()

    for toplevel_dir in sorted(scan_dict):
        scan_start = time.time()

        if SCAN_RECENTLY_MODIFIED_FILES_ONLY:
            logger.info("Finding files modified within the last %s in %s ...",
                        str(MTIME_DAYS) + " days" if MTIME_DAYS > 1 else "day", toplevel_dir)
            # Find the recently modified files in the given top level directory
            scan_list_file = NamedTemporaryFile(prefix='%s_scan_list.' % toplevel_dir[1:], mode='wb', delete=False)
            if 'include' in scan_dict[toplevel_dir]:
                walk_include_items(scan_dict[toplevel_dir]['include'], scan_list_file)
            else:
                walk_directory(toplevel_dir, scan_list_file)

            scan_list_file.flush()
            yara_cmd = "/usr/local/bin/yara -N -p 2 -r -C /tmp/signatures.yar --scan-list %s" % scan_list_file.name

        else:
            # Scan the top level directories as is
            if 'include' in scan_dict[toplevel_dir]:
                scan_list_file = NamedTemporaryFile(prefix='%s_scan_list.' % toplevel_dir[1:], mode='wb', delete=False)
                scan_list_file.write('\n'.join(scan_dict[toplevel_dir]['include']))
                scan_list_file.flush()
                yara_cmd = "/usr/local/bin/yara -N -p 2 -r -C /tmp/signatures.yar --scan-list %s" % scan_list_file.name
            else:
                yara_cmd = "/usr/local/bin/yara -N -p 2 -r -C /tmp/signatures.yar %s" % toplevel_dir

        logger.info("Yara command: %s", yara_cmd)
        logger.info("Scanning files in %s ...", toplevel_dir)
        try:
            stdout, stderr = subprocess.Popen(yara_cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE).communicate()
            scan_output = stdout.decode('utf-8').strip()
        except subprocess.CalledProcessError as err:
            logger.error("Unable to scan %s: %s", toplevel_dir, err.output.strip().decode('utf-8'))
            continue

        scan_end = time.time()
        logger.info("Processing time for %s: %d seconds", toplevel_dir, (scan_end - scan_start))
        logger.debug("Yara output:\n%s", scan_output)

    fs_scan_end = time.time()
    logger.info("Filesystem scan time: %s", time.strftime("%H:%M:%S", time.gmtime(fs_scan_end - fs_scan_start)))


if __name__ == '__main__':
    import logging
    from pprint import pprint

    logger.setLevel(logging.getLevelName('DEBUG'))

    scan_dict = process()
    pprint(scan_dict)
    scan(scan_dict)
